# Newspaper ETL Process

This project involves the comprehensive extraction, transformation, and loading (ETL) process of data from two big latin newspaper websites, 'El País' and 'La República,' using web scraping techniques and Python programming. Through web scraping, the project captures valuable textual and multimedia content from these news sources. Subsequently, Python scripts are employed to preprocess and clean the acquired data, ensuring its suitability for analysis and reporting.

The ETL process includes data extraction from the websites' various sections, such as news articles, opinion pieces, and multimedia content. Additionally, it involves the extraction of metadata, timestamps, and categorization tags for better content organization. Once collected, the data is subjected to transformation procedures to standardize formats, remove duplicates, and ensure data consistency. Finally, the loaded data is structured and stored for easy access and analysis, enabling insights and trends to be derived from the news articles and media assets.
